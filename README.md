# Awesome papers I read ðŸ¤©
Papers I read. Might or might not also contain my thoughts on it or annotations, or whatever.

So far I've read 13 papers!

## Basics

### Transformers
| Paper                                                                          | Publication Date | Read date | Notes |
|--------------------------------------------------------------------------------|------------------|-----------|-------|
| [Attention Is All You Need](https://arxiv.org/abs/1706.03762) AKA Transformers | 2017-06          | 2023-12   |       |

### Vision
| Paper                                                                                                                                        | Publication Date | Read date | Notes |
|----------------------------------------------------------------------------------------------------------------------------------------------|------------------|-----------|-------|
| [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) AKA Vision Transformers (ViT) | 2020-10          | 2024-01   |       |
| [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)                                  | 2021-03          | 2024-01   |       |

### Language
| Paper                                                                                                                | Publication Date | Read date | Notes |
|----------------------------------------------------------------------------------------------------------------------|------------------|-----------|-------|
| [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) | 2018-10          | 2024-01   |       |
| [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)                          | 2019-07          | 2024-01   |       |

### Multimodal
| Paper                                                                                                                                            | Publication Date | Read date | Notes |
|--------------------------------------------------------------------------------------------------------------------------------------------------|------------------|-----------|-------|
| [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)                              AKA CLIP  | 2021-03          | 2024-01   |       |
| [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/abs/2201.12086)     | 2022-01          | 2023      |       |
| [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)       | 2023-01          | 2023      |       |
| [Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)           AKA SigLIP                                            | 2023-03          | 2024-01   |       |

## Audio

### Speech Recognition
| Paper                                                                                                               | Publication Date | Read date | Notes                                                                                                    |
|---------------------------------------------------------------------------------------------------------------------|------------------|-----------|----------------------------------------------------------------------------------------------------------|
| [wav2vec: Unsupervised Pre-training for Speech Recognition](https://arxiv.org/abs/1904.05862)                       | 2019-04          | 2023-12   | [Link](notes/1904.05862-wav2vec-Unsupervised-Pre--training-for-Speech-Recognition.md)                    |
| [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477) | 2020-06          | 2024-01   | [Link](notes/2006.11477-wav2vec2-A-Framework-for-Self--Supervised-Learning-of-Speech-Representations.md) |
| [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356) AKA Whisper          | 2022-12          | 2024-01   | [Link](notes/whisper.md)                                                                                 |

## Parameter Efficient Training/Fine-tuning
| Paper                                                                                  | Publication Date | Read date | Comments |
|----------------------------------------------------------------------------------------|------------------|-----------|----------|
| [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) | 2021-06          | 2024-01   |          |
